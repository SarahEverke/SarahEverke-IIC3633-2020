## Crítica: *Item-Based Collaborative Filtering Recommendation Algorithms*

Rendle et. al proponen "criterio de optimización genérico para una clasificación personalizada óptima" que puede ser aplicado a diversos modelos de recomendadicón ya existentes. Como trabajan con *feedback* implícito se utilizan tuplas (u, i, j) que indican un usuario que *u* que interactúo con un ítem *i* y desconoce a un ítem *j*. Luego, mediante el teorema de Bayes y el estimador de verosimilitud obtienen una expresión que será optimizada.  A continuación, comentaré aspectos que consideré interesantes y las dudas que tuve luego de leer el *paper*.

Al optimizar se propone el uso del descenso del gradiente. Los autores calculan el descenso estocásticamente (que escoje las tuplas aleatoriamente) ya que en comparación del método *completo* converge más rápido. Esto es interesante porque en otras metodologías que se usa el descenso del gradiente como SVD se podría utilizar la versión estocástica para agilizar la convergencia. 

Como los autores diseñan un criterio de optimización es posible aplicarlo a metodologías ya existentes como k-NN y factorización matricial. Esto es útil porque permite utilizar modelos de *feedback* explícito cuando sólo hay datos implícitos. También, le entrega validez a la propuesta que hayan comparado sus resultados con otros modelos como WR-MF y MMMF y que utilizaran dos sets de datos. 

Como métrica escogieron AUC, aunque habría sido positivo que explicaran esa decisión. Podrían haber añadido la métrica *rank* que usaron Hu et al. en su *paper* para comparar los rendimientos según esa medición. En ambas pruebas los algoritmos que utilizaron el médoto de optimización de Rendle et al. tienen un menor error. No obstante, habría que comprobar la calidad de las recomendaciones en términos de si son novedosas para el usuario, es decir, ítems que el usuario no sabía que existían. 