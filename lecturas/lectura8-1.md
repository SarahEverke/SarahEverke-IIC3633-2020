# Crítica: *A user-centric evaluation framework for recommender systems*

Pu et. al proponen un marco de evaluación de sistemas recomendadores que se basa en las métricas de rendimiento-esfuerzo y el modelo de usuario-confianza. A continuación, comentaré aspectos que considero interesantes y las dudas que tuve luego de leer el texto.

Primero, en las métricas de rendimiento-esfuerzo propuestas creo que es interesante que en ambas considerasen información cuantitativa y cualitativa. Al considerar tanto la opinión como el comportamiento del usuario se obtiene un mejor acercamiento a cómo el usuario valora el sistema. 

Segundo, como miden a través de un cuestionario miden las variables subjetivas, es factible replicar el experimento y obtener datos que sean comparables. Sin embargo, esto es una limitación debido a que no pueden profundizar en la experiencia personal de cada usuario como lo haría por ejemplo una entrevista. 

Tercero, considero que faltó que hubiesen evaluado al menos un sistema recomendador con su propuesta. Especialmente, habría sido interesante comparar esta métrica con las métricas matemáticas, ya que se podría haber visto si existe una relación entre estas. 

Cuarto, no queda claro cómo combinar los valores subjetivos y objetivos de las métricas de precisión y esfuerzo. ¿Se ponderan con el mismo factor? ¿Se deben normalizar los valores antes de ser ponderados? 

Finalmente, el *paper* es interesante porque propone un mecanismo de evaluación que toma en consideración información objetiva y subjetiva. Sin embargo, faltó señalar cómo interpretar el resultado final. ¿Se obtiene un único valor tras aplicar el modelo? ¿Mientras mayor sea implica que el usuario confía más en las recomendaciones?
  


