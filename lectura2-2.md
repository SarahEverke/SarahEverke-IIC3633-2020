## Crítica: *Item-Based Collaborative Filtering Recommendation Algorithms*

Rendle et. al proponen "criterio de optimización genérico para una clasificación personalizada óptima" que puede ser aplicado a diversos modelos de recomendadicón ya existentes. Como trabajan con *feedback* implícito se utilizan tuplas (u, i, j) que indican un usuario que *u* que interactúo con un ítem *i* y desconoce a un ítem *j*. Luego, mediante el teorema de Bayes y el estimador de verosimilitud obtienen una expresión que será optimizada.  A continuación, comentaré aspectos que consideré interesantes y las dudas que tuve luego de leer el *paper*.

Al optimizar se propone el uso del descenso del gradiente. Los autores proponen calcular el descenso estocásticamente (que escoje las tuplas aleatoriamente) ya que en comparación del método *completo* converge más rápido. Esto es interesante porque en otras metodologías que se usa el descenso del gradiente como SVD se podría utilizar la versión estocástica para agilizar la convergencia. 

Como los autores diseñan un criterio de optimización es posible aplicarlo a metodologías ya existentes como k-NN y factorización matricial. Esto es útil porque permite utilizar modelos de *feedback* explícito cuando sólo hay datos implícitos. También, le entrega validez a la propuesta que hayan comparado sus resultados con otros modelos como WR-MF y MMMF. Como métrica escogieron AUC, aunque habría sido positivo que explicaran esa decisión. Tal vez, podrían haber añadido la métrica *rank* que usaron Hu et. al en su *paper* para comparar los rendimientos según esa medición. 